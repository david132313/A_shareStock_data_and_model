{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8L7E0ecOpsxeNmZR1IZvG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david132313/A_shareStock_data_and_model/blob/main/Update_dataBase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 0 — Mount Drive"
      ],
      "metadata": {
        "id": "_lUgb8_yFYJ3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRjOZVMIEsoI",
        "outputId": "d4134dd2-1439-4cd3-b228-947fc0c2cf4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 1 — 安装依赖"
      ],
      "metadata": {
        "id": "4ENGJpeSFdKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tushare tqdm pandas\n"
      ],
      "metadata": {
        "id": "8pvhYh4OFXcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc43fa6-7ffc-4dd4-c6e2-4ec31d3258be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 — 配置路径 + TuShare Token"
      ],
      "metadata": {
        "id": "04wtd0vbFij4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Config (env first; fallback to Colab Secrets)\n",
        "\n",
        "import os\n",
        "\n",
        "DB_DRIVE = \"/content/drive/MyDrive/AshareDB/db/ashare.sqlite\"\n",
        "DB_LOCAL = \"/content/ashare.sqlite\"   # local working copy for fast writes\n",
        "\n",
        "# 1) try environment variable first\n",
        "TUSHARE_TOKEN = os.environ.get(\"TUSHARE_TOKEN\", \"\")\n",
        "\n",
        "# 2) fallback to Colab Secrets (if env not set)\n",
        "if not TUSHARE_TOKEN:\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        # change this to EXACTLY your secret name in the left \"Secrets\" panel\n",
        "        TUSHARE_TOKEN = userdata.get(\"E_TOKEN\") or \"\"\n",
        "    except Exception:\n",
        "        TUSHARE_TOKEN = \"\"\n",
        "\n",
        "if not TUSHARE_TOKEN:\n",
        "    raise RuntimeError(\n",
        "        \"Missing TuShare token.\\n\"\n",
        "        \"Option A (env): %env TUSHARE_TOKEN=YOUR_TOKEN\\n\"\n",
        "        \"Option B (Secrets): set a secret named E_TOKEN (or update the name in this cell).\"\n",
        "    )\n",
        "\n",
        "print(\"DB_DRIVE:\", DB_DRIVE)\n",
        "print(\"DB_LOCAL:\", DB_LOCAL)\n",
        "print(\"TUSHARE_TOKEN loaded ✅ (hidden)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG2ucTFqFyTp",
        "outputId": "f439cdad-90fa-42ca-f62d-db88be5f4df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DB_DRIVE: /content/drive/MyDrive/AshareDB/db/ashare.sqlite\n",
            "DB_LOCAL: /content/ashare.sqlite\n",
            "TUSHARE_TOKEN loaded ✅ (hidden)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 3 — 打开 DB（本地备份 + 建表确保存在）"
      ],
      "metadata": {
        "id": "TJXekbbNI6iA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, sqlite3\n",
        "from datetime import datetime\n",
        "\n",
        "# 把 Drive DB 拷到本地\n",
        "shutil.copy2(DB_DRIVE, DB_LOCAL)\n",
        "print(\"copied DB to local:\", DB_LOCAL)\n",
        "\n",
        "def connect_sqlite(path: str) -> sqlite3.Connection:\n",
        "    conn = sqlite3.connect(path, timeout=60)\n",
        "    conn.isolation_level = None\n",
        "    conn.execute(\"PRAGMA journal_mode=WAL;\")\n",
        "    conn.execute(\"PRAGMA synchronous=NORMAL;\")\n",
        "    conn.execute(\"PRAGMA temp_store=MEMORY;\")\n",
        "    conn.execute(\"PRAGMA cache_size=-200000;\")\n",
        "    conn.execute(\"PRAGMA busy_timeout=60000;\")\n",
        "    return conn\n",
        "\n",
        "SCHEMA = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS security_map (\n",
        "  sec_id  INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "  ts_code TEXT NOT NULL UNIQUE\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS daily_price (\n",
        "  trade_date INTEGER NOT NULL,\n",
        "  sec_id     INTEGER NOT NULL,\n",
        "  open       REAL,\n",
        "  high       REAL,\n",
        "  low        REAL,\n",
        "  close      REAL,\n",
        "  pre_close  REAL,\n",
        "  change     REAL,\n",
        "  pct_chg    REAL,\n",
        "  vol        REAL,\n",
        "  amount     REAL,\n",
        "  PRIMARY KEY (trade_date, sec_id)\n",
        ");\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS ingest_manifest (\n",
        "  trade_date   INTEGER PRIMARY KEY,\n",
        "  parquet_file TEXT NOT NULL,\n",
        "  rows         INTEGER NOT NULL,\n",
        "  status       TEXT NOT NULL,\n",
        "  message      TEXT,\n",
        "  loaded_at    TEXT NOT NULL\n",
        ");\n",
        "\n",
        "CREATE INDEX IF NOT EXISTS idx_daily_date     ON daily_price(trade_date);\n",
        "CREATE INDEX IF NOT EXISTS idx_daily_sec_date ON daily_price(sec_id, trade_date);\n",
        "\"\"\"\n",
        "\n",
        "conn = connect_sqlite(DB_LOCAL)\n",
        "conn.executescript(SCHEMA)\n",
        "\n",
        "# 当前 DB 最大日期\n",
        "row = conn.execute(\"SELECT MAX(trade_date) FROM daily_price;\").fetchone()\n",
        "last_db_date = int(row[0]) if row and row[0] is not None else None\n",
        "print(\"DB last trade_date:\", last_db_date)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrXBvPRLIpWR",
        "outputId": "1fa618c0-0b20-4bcd-c02d-6e59e72b8c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copied DB to local: /content/ashare.sqlite\n",
            "DB last trade_date: 20251231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 4 — 用 TuShare 找“缺失交易日列表”"
      ],
      "metadata": {
        "id": "bgT7iDCoKurN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tushare as ts\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "ts.set_token(TUSHARE_TOKEN)\n",
        "pro = ts.pro_api()\n",
        "\n",
        "def yyyymmdd(i: int) -> str:\n",
        "    return str(i)\n",
        "\n",
        "# 计算 start/end：从 DB 最后一天的下一天开始\n",
        "if last_db_date is None:\n",
        "    # 如果 DB 为空（不太可能），你可以手动设起始日\n",
        "    start_date = \"20100101\"\n",
        "else:\n",
        "    # 下一天（这里用字符串简单加 1 天会麻烦，所以用 pandas）\n",
        "    dt = pd.to_datetime(str(last_db_date))\n",
        "    start_date = (dt + pd.Timedelta(days=1)).strftime(\"%Y%m%d\")\n",
        "\n",
        "# end_date 设为今天；trade_cal 会返回 <= today 的开市日\n",
        "end_date = pd.Timestamp.today().strftime(\"%Y%m%d\")\n",
        "print(\"Query trade_cal range:\", start_date, \"->\", end_date)\n",
        "\n",
        "cal = pro.trade_cal(exchange=\"SSE\", start_date=start_date, end_date=end_date, is_open=\"1\",\n",
        "                    fields=\"cal_date,is_open\")\n",
        "open_dates = cal[\"cal_date\"].tolist()\n",
        "print(\"open dates to consider:\", len(open_dates), \"first:\", (open_dates[0] if open_dates else None),\n",
        "      \"last:\", (open_dates[-1] if open_dates else None))\n",
        "\n",
        "# 如果某些日期你之前跑过但未写入（manifest fail），也可以强制重跑：\n",
        "# fail_dates = [str(r[0]) for r in conn.execute(\"SELECT trade_date FROM ingest_manifest WHERE status='fail' ORDER BY trade_date;\").fetchall()]\n",
        "# open_dates = sorted(set(open_dates + fail_dates))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IinCyIzgK65B",
        "outputId": "2cc92cab-5050-4bdd-d1e2-fa1079071aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query trade_cal range: 20260101 -> 20260110\n",
            "open dates to consider: 5 first: 20260109 last: 20260105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 5 — 增量更新入库（自动续跑/重试/一次性更新所有缺失日）"
      ],
      "metadata": {
        "id": "SAahCwo6LDMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "UPSERT_DAILY_SQL = \"\"\"\n",
        "INSERT INTO daily_price(\n",
        "  trade_date, sec_id, open, high, low, close, pre_close, change, pct_chg, vol, amount\n",
        ") VALUES (?,?,?,?,?,?,?,?,?,?,?)\n",
        "ON CONFLICT(trade_date, sec_id) DO UPDATE SET\n",
        "  open=excluded.open,\n",
        "  high=excluded.high,\n",
        "  low=excluded.low,\n",
        "  close=excluded.close,\n",
        "  pre_close=excluded.pre_close,\n",
        "  change=excluded.change,\n",
        "  pct_chg=excluded.pct_chg,\n",
        "  vol=excluded.vol,\n",
        "  amount=excluded.amount;\n",
        "\"\"\"\n",
        "\n",
        "# security_map cache\n",
        "cache_ts2id = {}\n",
        "for ts_code, sec_id in conn.execute(\"SELECT ts_code, sec_id FROM security_map;\"):\n",
        "    cache_ts2id[ts_code] = sec_id\n",
        "\n",
        "def ensure_sec_ids_cached(conn, codes):\n",
        "    new_codes = [c for c in codes if c not in cache_ts2id]\n",
        "    if not new_codes:\n",
        "        return\n",
        "    conn.executemany(\"INSERT OR IGNORE INTO security_map(ts_code) VALUES (?);\",\n",
        "                     [(c,) for c in set(new_codes)])\n",
        "    # 查回\n",
        "    uniq = sorted(set(new_codes))\n",
        "    for i in range(0, len(uniq), 900):\n",
        "        batch = uniq[i:i+900]\n",
        "        placeholders = \",\".join([\"?\"] * len(batch))\n",
        "        q = f\"SELECT ts_code, sec_id FROM security_map WHERE ts_code IN ({placeholders});\"\n",
        "        for ts_code, sec_id in conn.execute(q, batch):\n",
        "            cache_ts2id[ts_code] = sec_id\n",
        "\n",
        "def already_ok(trade_date_int: int) -> bool:\n",
        "    r = conn.execute(\"SELECT status FROM ingest_manifest WHERE trade_date=?;\", (trade_date_int,)).fetchone()\n",
        "    return (r is not None and r[0] == \"ok\")\n",
        "\n",
        "def fetch_daily_all(trade_date: str, max_retry=5, sleep_base=1.0) -> pd.DataFrame:\n",
        "    # TuShare: pro.daily(trade_date=YYYYMMDD) 返回全市场当日\n",
        "    for k in range(max_retry):\n",
        "        try:\n",
        "            df = pro.daily(trade_date=trade_date,\n",
        "                           fields=\"ts_code,trade_date,open,high,low,close,pre_close,change,pct_chg,vol,amount\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            if k == max_retry - 1:\n",
        "                raise\n",
        "            time.sleep(sleep_base * (2 ** k))\n",
        "\n",
        "ok = fail = skip = 0\n",
        "\n",
        "for d in tqdm(open_dates, desc=\"update daily\"):\n",
        "    td = int(d)\n",
        "    if already_ok(td):\n",
        "        skip += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        df = fetch_daily_all(d)\n",
        "        if df is None or df.empty:\n",
        "            # 有时最新日期 TuShare 还没更新，会返回空；记录并跳过\n",
        "            conn.execute(\"BEGIN;\")\n",
        "            conn.execute(\"\"\"\n",
        "            INSERT OR REPLACE INTO ingest_manifest(trade_date, parquet_file, rows, status, message, loaded_at)\n",
        "            VALUES (?,?,?,?,?,?)\n",
        "            \"\"\", (td, f\"tushare:{d}\", 0, \"fail\", \"empty daily from tushare (maybe not available yet)\",\n",
        "                  datetime.now().isoformat(timespec=\"seconds\")))\n",
        "            conn.execute(\"COMMIT;\")\n",
        "            fail += 1\n",
        "            continue\n",
        "\n",
        "        # 确保类型\n",
        "        df[\"trade_date\"] = df[\"trade_date\"].astype(str).astype(int)\n",
        "        codes = df[\"ts_code\"].astype(str).unique().tolist()\n",
        "\n",
        "        conn.execute(\"BEGIN;\")\n",
        "        ensure_sec_ids_cached(conn, codes)\n",
        "        df[\"sec_id\"] = df[\"ts_code\"].astype(str).map(cache_ts2id).astype(int)\n",
        "\n",
        "        df2 = df[[\"trade_date\",\"sec_id\",\"open\",\"high\",\"low\",\"close\",\"pre_close\",\"change\",\"pct_chg\",\"vol\",\"amount\"]]\n",
        "        df2 = df2.where(pd.notnull(df2), None)\n",
        "\n",
        "        conn.executemany(UPSERT_DAILY_SQL, df2.itertuples(index=False, name=None))\n",
        "\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT OR REPLACE INTO ingest_manifest(trade_date, parquet_file, rows, status, message, loaded_at)\n",
        "        VALUES (?,?,?,?,?,?)\n",
        "        \"\"\", (td, f\"tushare:{d}\", int(len(df2)), \"ok\", None,\n",
        "              datetime.now().isoformat(timespec=\"seconds\")))\n",
        "\n",
        "        conn.execute(\"COMMIT;\")\n",
        "        ok += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            conn.execute(\"ROLLBACK;\")\n",
        "        except Exception:\n",
        "            pass\n",
        "        conn.execute(\"BEGIN;\")\n",
        "        conn.execute(\"\"\"\n",
        "        INSERT OR REPLACE INTO ingest_manifest(trade_date, parquet_file, rows, status, message, loaded_at)\n",
        "        VALUES (?,?,?,?,?,?)\n",
        "        \"\"\", (td, f\"tushare:{d}\", 0, \"fail\", repr(e),\n",
        "              datetime.now().isoformat(timespec=\"seconds\")))\n",
        "        conn.execute(\"COMMIT;\")\n",
        "        fail += 1\n",
        "\n",
        "print(\"update done | ok:\", ok, \"fail:\", fail, \"skip:\", skip, \"| mapping cache:\", len(cache_ts2id))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1S9MjKfK_CA",
        "outputId": "2ab75fda-b44a-4f39-d497-053189eb3ee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "update daily: 100%|██████████| 5/5 [00:11<00:00,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update done | ok: 5 fail: 0 skip: 0 | mapping cache: 5790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 6 — 一次性写回 Drive（生成“干净主库”，避免 -wal/-shm 残留）"
      ],
      "metadata": {
        "id": "TazLqY3_MDw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3, os\n",
        "\n",
        "def backup_local_to_drive(local_conn: sqlite3.Connection, drive_path: str):\n",
        "    tmp = drive_path + \".tmp\"\n",
        "    dst = sqlite3.connect(tmp)\n",
        "    try:\n",
        "        local_conn.backup(dst)\n",
        "        dst.commit()\n",
        "    finally:\n",
        "        dst.close()\n",
        "    os.replace(tmp, drive_path)\n",
        "\n",
        "backup_local_to_drive(conn, DB_DRIVE)\n",
        "\n",
        "print(\"saved to Drive:\", DB_DRIVE, \"size(MB)=\", os.path.getsize(DB_DRIVE)/1024/1024)\n",
        "print(\"integrity_check:\", conn.execute(\"PRAGMA integrity_check;\").fetchone()[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq-ocNtTMXB0",
        "outputId": "6a8767c5-7055-4c35-869e-ae67bace365c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to Drive: /content/drive/MyDrive/AshareDB/db/ashare.sqlite size(MB)= 2298.1640625\n",
            "integrity_check: ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 7 — 验证更新结果（日期范围/失败日）"
      ],
      "metadata": {
        "id": "JAsriIulNS8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(pd.read_sql_query(\"\"\"\n",
        "SELECT MIN(trade_date) AS min_date, MAX(trade_date) AS max_date, COUNT(*) AS total_rows\n",
        "FROM daily_price;\n",
        "\"\"\", conn))\n",
        "\n",
        "print(pd.read_sql_query(\"\"\"\n",
        "SELECT status, COUNT(*) AS n\n",
        "FROM ingest_manifest\n",
        "GROUP BY status;\n",
        "\"\"\", conn))\n",
        "\n",
        "print(pd.read_sql_query(\"\"\"\n",
        "SELECT trade_date, parquet_file, message\n",
        "FROM ingest_manifest\n",
        "WHERE status='fail'\n",
        "ORDER BY trade_date DESC\n",
        "LIMIT 20;\n",
        "\"\"\", conn))\n",
        "\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIAqFCt3NSsv",
        "outputId": "1c14e1a6-4761-4cc0-e895-dd896299329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   min_date  max_date  total_rows\n",
            "0  20000104  20260109    16501185\n",
            "  status     n\n",
            "0     ok  6306\n",
            "Empty DataFrame\n",
            "Columns: [trade_date, parquet_file, message]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "PQvpcCS-L5h8"
      }
    }
  ]
}